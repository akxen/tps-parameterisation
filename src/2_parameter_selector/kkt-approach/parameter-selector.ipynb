{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Selector\n",
    "Implements bi-level optimisation model to calibrate a tradable performance standard to achieve environmental and economic objectives.\n",
    "\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "from math import pi\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyomo.environ import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths\n",
    "Paths to relevant data and output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectoryPaths(object):\n",
    "    \"Paths to relevant directories\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_dir = os.path.join(os.path.curdir, os.path.pardir, os.path.pardir, os.path.pardir, 'data')\n",
    "        self.scenarios_dir = os.path.join(os.path.curdir, os.path.pardir, os.path.pardir, '1_create_scenarios')\n",
    "        self.output_dir = os.path.join(os.path.curdir, 'output')\n",
    "\n",
    "paths = DirectoryPaths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model data\n",
    "Import raw model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawData(object):\n",
    "    \"Collect input data\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Paths to directories\n",
    "        DirectoryPaths.__init__(self)\n",
    "        \n",
    "        \n",
    "        # Network data\n",
    "        # ------------\n",
    "        # Nodes\n",
    "        self.df_n = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'network', 'network_nodes.csv'), index_col='NODE_ID')\n",
    "\n",
    "        # AC edges\n",
    "        self.df_e = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'network', 'network_edges.csv'), index_col='LINE_ID')\n",
    "\n",
    "        # HVDC links\n",
    "        self.df_hvdc_links = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'network', 'network_hvdc_links.csv'), index_col='HVDC_LINK_ID')\n",
    "\n",
    "        # AC interconnector links\n",
    "        self.df_ac_i_links = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'network', 'network_ac_interconnector_links.csv'), index_col='INTERCONNECTOR_ID')\n",
    "\n",
    "        # AC interconnector flow limits\n",
    "        self.df_ac_i_limits = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'network', 'network_ac_interconnector_flow_limits.csv'), index_col='INTERCONNECTOR_ID')\n",
    "\n",
    "\n",
    "        # Generators\n",
    "        # ----------       \n",
    "        # Generating unit information\n",
    "        self.df_g = pd.read_csv(os.path.join(self.data_dir, 'egrimod-nem-dataset-v1.3', 'akxen-egrimod-nem-dataset-4806603', 'generators', 'generators.csv'), index_col='DUID', dtype={'NODE': int})\n",
    "        self.df_g['SRMC_2016-17'] = self.df_g['SRMC_2016-17'].map(lambda x: x + np.random.uniform(0, 2))\n",
    "        \n",
    "               \n",
    "        # Operating scenarios\n",
    "        # -------------------\n",
    "        with open(os.path.join(paths.scenarios_dir, 'output', '2_scenarios.pickle'), 'rb') as f:\n",
    "            self.df_scenarios = pickle.load(f)\n",
    "\n",
    "# Create object containing raw model data\n",
    "raw_data = RawData() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organise model data\n",
    "Format and organise data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrganiseData(object):\n",
    "    \"Organise data to be used in mathematical program\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Load model data\n",
    "        RawData.__init__(self)\n",
    "        \n",
    "\n",
    "    def get_admittance_matrix(self):\n",
    "        \"Construct admittance matrix for network\"\n",
    "\n",
    "        # Initialise dataframe\n",
    "        df_Y = pd.DataFrame(data=0j, index=self.df_n.index, columns=self.df_n.index)\n",
    "\n",
    "        # Off-diagonal elements\n",
    "        for index, row in self.df_e.iterrows():\n",
    "            fn, tn = row['FROM_NODE'], row['TO_NODE']\n",
    "            df_Y.loc[fn, tn] += - (1 / (row['R_PU'] + 1j * row['X_PU'])) * row['NUM_LINES']\n",
    "            df_Y.loc[tn, fn] += - (1 / (row['R_PU'] + 1j * row['X_PU'])) * row['NUM_LINES']\n",
    "\n",
    "        # Diagonal elements\n",
    "        for i in self.df_n.index:\n",
    "            df_Y.loc[i, i] = - df_Y.loc[i, :].sum()\n",
    "\n",
    "        # Add shunt susceptance to diagonal elements\n",
    "        for index, row in self.df_e.iterrows():\n",
    "            fn, tn = row['FROM_NODE'], row['TO_NODE']\n",
    "            df_Y.loc[fn, fn] += (row['B_PU'] / 2) * row['NUM_LINES']\n",
    "            df_Y.loc[tn, tn] += (row['B_PU'] / 2) * row['NUM_LINES']\n",
    "\n",
    "        return df_Y\n",
    "    \n",
    "    \n",
    "    def get_HVDC_incidence_matrix(self):\n",
    "        \"Incidence matrix for HVDC links\"\n",
    "        \n",
    "        # Incidence matrix for HVDC links\n",
    "        df = pd.DataFrame(index=self.df_n.index, columns=self.df_hvdc_links.index, data=0)\n",
    "\n",
    "        for index, row in self.df_hvdc_links.iterrows():\n",
    "            # From nodes assigned a value of 1\n",
    "            df.loc[row['FROM_NODE'], index] = 1\n",
    "\n",
    "            # To nodes assigned a value of -1\n",
    "            df.loc[row['TO_NODE'], index] = -1\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def get_all_ac_edges(self):\n",
    "        \"Tuples defining from and to nodes for all AC edges (forward and reverse)\"\n",
    "        \n",
    "        # Set of all AC edges\n",
    "        edge_set = set()\n",
    "        \n",
    "        # Loop through edges, add forward and reverse direction indice tuples to set\n",
    "        for index, row in model_data.df_e.iterrows():\n",
    "            edge_set.add((row['FROM_NODE'], row['TO_NODE']))\n",
    "            edge_set.add((row['TO_NODE'], row['FROM_NODE']))\n",
    "        \n",
    "        return edge_set\n",
    "    \n",
    "    def get_network_graph(self):\n",
    "        \"Graph containing connections between all network nodes\"\n",
    "        network_graph = {n: set() for n in model_data.df_n.index}\n",
    "\n",
    "        for index, row in model_data.df_e.iterrows():\n",
    "            network_graph[row['FROM_NODE']].add(row['TO_NODE'])\n",
    "            network_graph[row['TO_NODE']].add(row['FROM_NODE'])\n",
    "        \n",
    "        return network_graph\n",
    "    \n",
    "    \n",
    "    def get_all_dispatchable_fossil_generator_duids(self):\n",
    "        \"Fossil dispatch generator DUIDs\"\n",
    "        \n",
    "        # Filter - keeping only fossil and scheduled generators\n",
    "        mask = (model_data.df_g['FUEL_CAT'] == 'Fossil') & (model_data.df_g['SCHEDULE_TYPE'] == 'SCHEDULED')\n",
    "        \n",
    "        return model_data.df_g[mask].index    \n",
    "    \n",
    "    \n",
    "    def get_intermittent_dispatch(self):\n",
    "        \"Dispatch from intermittent generators (solar, wind)\"\n",
    "        \n",
    "        # Intermittent generator DUIDs\n",
    "        intermittent_duids_mask = model_data.df_g['FUEL_CAT'].isin(['Wind', 'Solar'])\n",
    "        intermittent_duids = model_data.df_g.loc[intermittent_duids_mask].index\n",
    "\n",
    "        # Intermittent dispatch aggregated by node\n",
    "        intermittent_dispatch =(model_data.df_dispatch.reindex(columns=intermittent_duids, fill_value=0)\n",
    "                                .T\n",
    "                                .join(model_data.df_g[['NODE']])\n",
    "                                .groupby('NODE').sum()\n",
    "                                .reindex(index=model_data.df_n.index, fill_value=0)\n",
    "                                .T)\n",
    "        \n",
    "        # Make sure columns are of type datetime\n",
    "        intermittent_dispatch.index = intermittent_dispatch.index.astype('datetime64[ns]')\n",
    "        \n",
    "        return intermittent_dispatch\n",
    "    \n",
    "    \n",
    "    def get_hydro_dispatch(self):\n",
    "        \"Dispatch from hydro plant\"\n",
    "        \n",
    "        # Dispatch from hydro plant\n",
    "        hydro_duids_mask = self.df_g['FUEL_CAT'].isin(['Hydro'])\n",
    "        hydro_duids = self.df_g.loc[hydro_duids_mask].index\n",
    "\n",
    "        # Hydro plant dispatch aggregated by node\n",
    "        hydro_dispatch = (self.df_dispatch.reindex(columns=hydro_duids, fill_value=0)\n",
    "                          .T\n",
    "                          .join(model_data.df_g[['NODE']])\n",
    "                          .groupby('NODE').sum()\n",
    "                          .reindex(index=self.df_n.index, fill_value=0)\n",
    "                          .T)\n",
    "        \n",
    "        # Make sure columns are of type datetime\n",
    "        hydro_dispatch.index = hydro_dispatch.index.astype('datetime64[ns]')\n",
    "        \n",
    "        return hydro_dispatch\n",
    "    \n",
    "    \n",
    "    def get_reference_nodes(self):\n",
    "        \"Get reference node IDs\"\n",
    "        \n",
    "        # Filter Regional Reference Nodes (RRNs) in Tasmania and Victoria.\n",
    "        mask = (model_data.df_n['RRN'] == 1) & (model_data.df_n['NEM_REGION'].isin(['TAS1', 'VIC1']))\n",
    "        reference_node_ids = model_data.df_n[mask].index\n",
    "        \n",
    "        return reference_node_ids\n",
    "    \n",
    "    \n",
    "    def get_node_demand(self):   \n",
    "        \"Compute demand at each node for a given time period, t\"\n",
    "\n",
    "        def _node_demand(row):\n",
    "            # NEM region for a given node\n",
    "            region = row['NEM_REGION']\n",
    "\n",
    "            # Load at node\n",
    "            demand = self.df_load.loc[:, region] * row['PROP_REG_D']\n",
    "\n",
    "            return demand\n",
    "        node_demand = self.df_n.apply(_node_demand, axis=1).T\n",
    "        \n",
    "        return node_demand\n",
    "    \n",
    "    \n",
    "    def get_generator_node_map(self, generators):\n",
    "        \"Get set of generators connected to each node\"\n",
    "        generator_node_map = (self.df_g.reindex(index=generators)\n",
    "                              .reset_index()\n",
    "                              .rename(columns={'OMEGA_G': 'DUID'})\n",
    "                              .groupby('NODE').agg(lambda x: set(x))['DUID']\n",
    "                              .reindex(self.df_n.index, fill_value=set()))\n",
    "        \n",
    "        return generator_node_map\n",
    "    \n",
    "    \n",
    "    def get_ac_interconnector_branches(self):\n",
    "        \"Get all AC interconnector branches - check that flow directions for each branch are correct\"\n",
    "\n",
    "        # Check that from and to regions conform with regional power flow limit directions\n",
    "        def check_flow_direction(row):\n",
    "            if (row['FROM_REGION'] == self.df_ac_i_limits.loc[row.name, 'FROM_REGION']) & (row['TO_REGION'] == model_data.df_ac_i_limits.loc[row.name, 'TO_REGION']):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        # Flow directions are consistent between link and limit DataFrames if True\n",
    "        flow_directions_conform = self.df_ac_i_links.apply(check_flow_direction, axis=1).all()\n",
    "        if flow_directions_conform:\n",
    "            print('Flow directions conform with regional flow limit directions: {0}'.format(flow_directions_conform))\n",
    "        else:\n",
    "            raise(Exception('Link flow directions inconsitent with regional flow forward limit definition'))\n",
    "\n",
    "        # Forward links\n",
    "        forward_links = self.df_ac_i_links.apply(lambda x: pd.Series({'INTERCONNECTOR_ID': '-'.join([x.name, 'FORWARD']), 'BRANCH': (x['FROM_NODE'], x['TO_NODE'])}), axis=1).set_index('INTERCONNECTOR_ID')\n",
    "        \n",
    "        # Reverse links\n",
    "        reverse_links = self.df_ac_i_links.apply(lambda x: pd.Series({'INTERCONNECTOR_ID': '-'.join([x.name, 'REVERSE']), 'BRANCH': (x['TO_NODE'], x['FROM_NODE'])}), axis=1).set_index('INTERCONNECTOR_ID')\n",
    "        \n",
    "        # Combine forward and reverse links\n",
    "        df = pd.concat([forward_links, reverse_links]).reset_index()\n",
    "        \n",
    "        # Construct branch ID\n",
    "        df['BRANCH_ID'] = df.apply(lambda x: '_'.join(['L', str(x.name + 1)]), axis=1)\n",
    "        df.set_index('BRANCH_ID', inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def get_ac_interconnector_flow_limits(self):\n",
    "        \"Get aggregate flow limits for each interconnector direction (both forward and reverse)\"\n",
    "        \n",
    "        # Forward limits\n",
    "        forward_limits = self.df_ac_i_limits.apply(lambda x: pd.Series({'LIMIT': x['FORWARD_LIMIT_MW'], 'INTERCONNECTOR_ID': '-'.join([x.name, 'FORWARD'])}), axis=1).set_index('INTERCONNECTOR_ID')\n",
    "\n",
    "        # Reverse limits\n",
    "        reverse_limits = self.df_ac_i_limits.apply(lambda x: pd.Series({'LIMIT': x['REVERSE_LIMIT_MW'], 'INTERCONNECTOR_ID': '-'.join([x.name, 'REVERSE'])}), axis=1).set_index('INTERCONNECTOR_ID')\n",
    "\n",
    "        # Combine forward and reverse limits\n",
    "        interconnector_limits = pd.concat([forward_limits, reverse_limits])\n",
    "        \n",
    "        return interconnector_limits\n",
    "    \n",
    "    \n",
    "    def get_ac_interconnector_branch_ids(self):\n",
    "        \"Get branch IDs that consitute each interconnector\"\n",
    "        \n",
    "        # Branch IDs for each interconnector\n",
    "        df = self.get_ac_interconnector_branches().reset_index().groupby('INTERCONNECTOR_ID').apply(lambda x: list(x['BRANCH_ID']))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def get_ac_interconnector_branch_node_incidence_matrix(self):\n",
    "        \"Incidence matrix showing if AC interconnector branch is defined as (+) or (-) flow for each node\"\n",
    "        \n",
    "        # Branches constituting AC interconnectors\n",
    "        interconnector_branches = self.get_ac_interconnector_branches()\n",
    "\n",
    "        # Initialise interconnector branch - node incidence matrix\n",
    "        df = pd.DataFrame(index=interconnector_branches.index, columns=self.df_n.index, data=0)\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            # Branch from node\n",
    "            from_node = interconnector_branches.loc[index, 'BRANCH'][0]\n",
    "\n",
    "            # Branch to node\n",
    "            to_node = interconnector_branches.loc[index, 'BRANCH'][1]\n",
    "\n",
    "            # Update values in matrix\n",
    "            df.loc[index, from_node] = 1\n",
    "            df.loc[index, to_node] = -1\n",
    "\n",
    "        return df.T\n",
    "\n",
    "# Create object containing organised model data\n",
    "model_data = OrganiseData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model(use_pu=None, variable_baseline=None, objective_type=None):\n",
    "    \"\"\"Create TPS baseline selection model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    use_pu : bool\n",
    "        Define if per-unit normalisation should be used. Re-scales parameters by system base power.\n",
    "    \n",
    "    variable_baseline : bool\n",
    "        Specify if the baseline should be treated as a variable. E.g. find baseline that delivers given objective.\n",
    "        \n",
    "    objective_type : str\n",
    "        Options:\n",
    "            'feasibility' - find a feasible solution for given baseline\n",
    "            'permit_price_target' - find baseline that delivers given permit price\n",
    "            'weighted_rrn_price_target' - find baseline that targets weighted regional reference node (RRN) prices\n",
    "            'nodal_electricity_price_target' - find baseline that targets nodal prices\n",
    "            'minimise_electricity_price' - find baseline that minimises average wholesale electricity price\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "    model : Pyomo model object\n",
    "        Model object contains constraints and objectives corresponding to the given objective type\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check parameters correctly specified\n",
    "    if (use_pu is None) or (variable_baseline is None):\n",
    "        raise(Exception('Must specify if baseline is variable, if per-unit system should be used, and type of objective for which model should be optimised'))\n",
    "    \n",
    "    \n",
    "    # Mapping functions\n",
    "    # -----------------\n",
    "    def f_1(g):\n",
    "        \"Given generator, g, return the index of the node to which it is connected\"\n",
    "        return int(model_data.df_g.loc[g, 'NODE'])\n",
    "\n",
    "    def f_2(h):\n",
    "        \"Given HVDC link, h, return the index of the link's 'from' node\"\n",
    "        return int(model_data.df_hvdc_links.loc[h, 'FROM_NODE'])\n",
    "\n",
    "    def f_3(h):\n",
    "        \"Given HVDC link, h, return the index of the link's 'to' node\"\n",
    "        return int(model_data.df_hvdc_links.loc[h, 'TO_NODE'])\n",
    "    \n",
    "    def f_4(r):\n",
    "        \"Given NEM region, r, return index of region's Regional Reference Node (RRN)\"\n",
    "        return int(model_data.df_n[model_data.df_n['RRN'] == 1].reset_index().set_index('NEM_REGION').loc[r, 'NODE_ID'])\n",
    "\n",
    "\n",
    "    # Construct model\n",
    "    # ---------------\n",
    "    # Initialise model\n",
    "    model = ConcreteModel()\n",
    "\n",
    "\n",
    "    # Sets\n",
    "    # ----   \n",
    "    # Nodes\n",
    "    model.OMEGA_N = Set(initialize=model_data.df_n.index)\n",
    "\n",
    "    # Generators\n",
    "    model.OMEGA_G = Set(initialize=model_data.get_all_dispatchable_fossil_generator_duids())\n",
    "\n",
    "    # AC edges\n",
    "    ac_edges = model_data.get_all_ac_edges()\n",
    "    model.OMEGA_NM = Set(initialize=ac_edges)\n",
    "\n",
    "    # Sets of branches for which aggregate AC interconnector limits are defined\n",
    "    ac_interconnector_flow_limits = model_data.get_ac_interconnector_flow_limits()\n",
    "    model.OMEGA_J = Set(initialize=ac_interconnector_flow_limits.index)\n",
    "\n",
    "    # HVDC links\n",
    "    model.OMEGA_H = Set(initialize=model_data.df_hvdc_links.index)\n",
    "\n",
    "    # Operating scenarios\n",
    "    model.OMEGA_S = Set(initialize=model_data.df_scenarios.columns)\n",
    "    \n",
    "    # NEM regions\n",
    "    model.OMEGA_R = Set(initialize=model_data.df_n['NEM_REGION'].unique())\n",
    "    \n",
    "    # Branches which constitute AC interconnectors in the network\n",
    "    ac_interconnector_branch_node_incidence_matrix = model_data.get_ac_interconnector_branch_node_incidence_matrix()\n",
    "    model.OMEGA_L = Set(initialize=ac_interconnector_branch_node_incidence_matrix.columns)\n",
    "\n",
    "\n",
    "    # Maps\n",
    "    # ----\n",
    "    # Generator-node map\n",
    "    generator_node_map = model_data.get_generator_node_map(model.OMEGA_G)\n",
    "\n",
    "    # Network graph\n",
    "    network_graph = model_data.get_network_graph()\n",
    "\n",
    "    # Interconnectors and the branches to from which they are constituted\n",
    "    ac_interconnector_branch_ids = model_data.get_ac_interconnector_branch_ids()\n",
    "    \n",
    "    # From and to nodes for each interconnector branch\n",
    "    ac_interconnector_branches = model_data.get_ac_interconnector_branches()\n",
    "\n",
    "\n",
    "    # Parameters\n",
    "    # ----------\n",
    "    # System base power\n",
    "    model.BASE_POWER = Param(initialize=100)\n",
    "    \n",
    "    # Emissions intensity baseline (fixed)\n",
    "    model.PHI = Param(initialize=0.95, mutable=True)\n",
    "\n",
    "    # Admittance matrix\n",
    "    admittance_matrix = model_data.get_admittance_matrix()\n",
    "    def B_RULE(model, n, m):\n",
    "        admittance_matrix_element = float(np.imag(admittance_matrix.loc[n, m]))\n",
    "        if use_pu:\n",
    "            return admittance_matrix_element\n",
    "        else:\n",
    "            return model.BASE_POWER * admittance_matrix_element\n",
    "    model.B = Param(model.OMEGA_NM, rule=B_RULE)\n",
    "\n",
    "    def P_H_MAX_RULE(s, h):\n",
    "        forward_flow_limit = float(model_data.df_hvdc_links.loc[h, 'FORWARD_LIMIT_MW'])\n",
    "        if use_pu:\n",
    "            return forward_flow_limit / model.BASE_POWER\n",
    "        else:\n",
    "            return forward_flow_limit\n",
    "    model.P_H_MAX = Param(model.OMEGA_H, rule=P_H_MAX_RULE)\n",
    "\n",
    "    def P_H_MIN_RULE(s, h):\n",
    "        reverse_flow_limit = float(model_data.df_hvdc_links.loc[h, 'REVERSE_LIMIT_MW'])\n",
    "        if use_pu:\n",
    "            return - reverse_flow_limit / model.BASE_POWER\n",
    "        else:\n",
    "            return - reverse_flow_limit\n",
    "    model.P_H_MIN = Param(model.OMEGA_H, rule=P_H_MIN_RULE)\n",
    "\n",
    "    # Reference nodes\n",
    "    reference_nodes = model_data.get_reference_nodes()\n",
    "    def S_R_RULE(model, n):\n",
    "        if n in reference_nodes:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    model.S_R = Param(model.OMEGA_N, rule=S_R_RULE)\n",
    "    \n",
    "    # Maximum generator output\n",
    "    def P_MAX_RULE(model, g):\n",
    "        registered_capacity = float(model_data.df_g.loc[g, 'REG_CAP'])\n",
    "        if use_pu:\n",
    "            return registered_capacity / model.BASE_POWER\n",
    "        else:\n",
    "            return registered_capacity\n",
    "    model.P_MAX = Param(model.OMEGA_G, rule=P_MAX_RULE)\n",
    "\n",
    "    # Minimum generator output (set to 0)\n",
    "    def P_MIN_RULE(model, g):\n",
    "        minimum_output = 0\n",
    "        if use_pu:\n",
    "            return minimum_output / model.BASE_POWER\n",
    "        else:\n",
    "            return minimum_output\n",
    "    model.P_MIN = Param(model.OMEGA_G, rule=P_MIN_RULE)\n",
    "\n",
    "    # Generator short-run marginal costs\n",
    "    def C_RULE(model, g):\n",
    "        marginal_cost = float(model_data.df_g.loc[g, 'SRMC_2016-17'])\n",
    "        if use_pu:\n",
    "            return marginal_cost / model.BASE_POWER\n",
    "        else:\n",
    "            return marginal_cost\n",
    "    model.C = Param(model.OMEGA_G, rule=C_RULE)\n",
    "\n",
    "    # Generator emissions intensities\n",
    "    def E_RULE(model, g):\n",
    "        return float(model_data.df_g.loc[g, 'EMISSIONS'])\n",
    "    model.E = Param(model.OMEGA_G, rule=E_RULE)\n",
    "\n",
    "    # Max voltage angle difference between connected nodes\n",
    "    model.THETA_DELTA = Param(initialize=float(pi / 2), mutable=True)\n",
    "\n",
    "    # HVDC incidence matrix\n",
    "    hvdc_incidence_matrix = model_data.get_HVDC_incidence_matrix()\n",
    "    def K_RULE(model, n, h):\n",
    "        return float(hvdc_incidence_matrix.loc[n, h])\n",
    "    model.K = Param(model.OMEGA_N, model.OMEGA_H, rule=K_RULE)    \n",
    "\n",
    "    # AC interconnector incidence matrix\n",
    "    def S_L_RULE(model, n, l):\n",
    "        return float(ac_interconnector_branch_node_incidence_matrix.loc[n, l])\n",
    "    model.S_L = Param(model.OMEGA_N, model.OMEGA_L, rule=S_L_RULE)\n",
    "\n",
    "    # Aggregate AC interconnector flow limits\n",
    "    ac_interconnector_flow_limits = model_data.get_ac_interconnector_flow_limits()\n",
    "    def F_RULE(model, j):\n",
    "        power_flow_limit = float(ac_interconnector_flow_limits.loc[j, 'LIMIT'])\n",
    "        if use_pu:\n",
    "            return power_flow_limit / model.BASE_POWER\n",
    "        else:\n",
    "            return power_flow_limit\n",
    "    model.F = Param(model.OMEGA_J, rule=F_RULE)\n",
    "\n",
    "    # Big-M parameters\n",
    "    def M_11_RULE(model, g):\n",
    "        return model.P_MAX[g] - model.P_MIN[g]\n",
    "    model.M_11 = Param(model.OMEGA_G, rule=M_11_RULE)\n",
    "\n",
    "    def M_12_RULE(model, g):\n",
    "        bound = 1e3\n",
    "        if use_pu:\n",
    "            return bound / model.BASE_POWER\n",
    "        else:\n",
    "            return bound\n",
    "    model.M_12 = Param(model.OMEGA_G, rule=M_12_RULE)\n",
    "\n",
    "    def M_21_RULE(model, g):\n",
    "        return model.P_MAX[g] - model.P_MIN[g]\n",
    "    model.M_21 = Param(model.OMEGA_G, rule=M_21_RULE)\n",
    "\n",
    "    def M_22_RULE(model, g):\n",
    "        bound = 1e3\n",
    "        if use_pu:\n",
    "            return bound / model.BASE_POWER\n",
    "        else:\n",
    "            return bound\n",
    "    model.M_22 = Param(model.OMEGA_G, rule=M_22_RULE)\n",
    "\n",
    "    def M_31_RULE(model, n, m):\n",
    "        return float(pi)\n",
    "    model.M_31 = Param(model.OMEGA_NM, rule=M_31_RULE)\n",
    "\n",
    "    def M_32_RULE(model, n, m):\n",
    "        bound = 1e3\n",
    "        if use_pu:\n",
    "            return bound / model.BASE_POWER\n",
    "        else:\n",
    "            return bound\n",
    "    model.M_32 = Param(model.OMEGA_NM, rule=M_32_RULE)\n",
    "\n",
    "    def M_41_RULE(model, j):\n",
    "        if 'REVERSE' in j:\n",
    "            new_index = j.replace('REVERSE', 'FORWARD')\n",
    "        elif 'FORWARD' in j:\n",
    "            new_index = j.replace('FORWARD', 'REVERSE')\n",
    "        else:\n",
    "            raise(Exception('REVERSE / FORWARD not in index name'))\n",
    "        return model.F[j] + model.F[new_index]\n",
    "    model.M_41 = Param(model.OMEGA_J, rule=M_41_RULE)\n",
    "\n",
    "    def M_42_RULE(model, j):\n",
    "        bound = 1e3\n",
    "        if use_pu:\n",
    "            return bound / model.BASE_POWER\n",
    "        else:\n",
    "            return bound\n",
    "    model.M_42 = Param(model.OMEGA_J, rule=M_42_RULE)\n",
    "\n",
    "    def M_51_RULE(model, h):\n",
    "        return model.P_H_MAX[h] - model.P_H_MIN[h]\n",
    "    model.M_51 = Param(model.OMEGA_H, rule=M_51_RULE)\n",
    "\n",
    "    def M_52_RULE(model, h):\n",
    "        bound = 1e3\n",
    "        if use_pu:\n",
    "            return bound / model.BASE_POWER\n",
    "        else:\n",
    "            return bound\n",
    "    model.M_52 = Param(model.OMEGA_H, rule=M_52_RULE)\n",
    "\n",
    "    def M_61_RULE(model, h):\n",
    "        return model.P_H_MAX[h] - model.P_H_MIN[h]\n",
    "    model.M_61 = Param(model.OMEGA_H, rule=M_61_RULE)\n",
    "\n",
    "    def M_62_RULE(model, h):\n",
    "        bound = 1e3\n",
    "        if use_pu:\n",
    "            return bound / model.BASE_POWER\n",
    "        else:\n",
    "            return bound\n",
    "    model.M_62 = Param(model.OMEGA_H, rule=M_62_RULE)\n",
    "\n",
    "    def M_71_RULE(model):\n",
    "        bound = 1e4\n",
    "        if use_pu:\n",
    "            return 1e4 / model.BASE_POWER\n",
    "        else:\n",
    "            return bound\n",
    "    model.M_71 = Param(rule=M_71_RULE)\n",
    "\n",
    "    def M_72_RULE(model):\n",
    "        bound = 1e4\n",
    "        if use_pu:\n",
    "            return bound / model.BASE_POWER\n",
    "        else:\n",
    "            return bound\n",
    "    model.M_72 = Param(rule=M_72_RULE)\n",
    "\n",
    "\n",
    "    # Variables\n",
    "    # ---------\n",
    "    # Permit market constraint dual variable\n",
    "    model.tau = Var()\n",
    "\n",
    "    # Permit market constraint binary variable\n",
    "    model.GAMMA_7 = Var(within=Binary)\n",
    "\n",
    "    # Additional sets, parameters, variable, and constraints if baseline is variable\n",
    "    if variable_baseline:\n",
    "        # Largest integer for baseline selection parameter index\n",
    "        model.U = 10\n",
    "\n",
    "        # Set of integers used to select discretized baseline\n",
    "        model.OMEGA_U = Set(initialize=range(0, model.U + 1))\n",
    "\n",
    "        # Minimum emissions intensity baseline\n",
    "        def PHI_MIN_RULE(model):\n",
    "            return float(0.8)\n",
    "        model.PHI_MIN = Param(rule=PHI_MIN_RULE)\n",
    "\n",
    "        # Maximum emissions intensity baseline\n",
    "        def PHI_MAX_RULE(model):\n",
    "            return float(1.3)\n",
    "        model.PHI_MAX = Param(rule=PHI_MAX_RULE)\n",
    "\n",
    "        # Emissions intensity baseline increment\n",
    "        model.PHI_DELTA = Param(initialize=float((model.PHI_MAX - model.PHI_MIN) / (2**model.U)))\n",
    "\n",
    "        # Parameter equal 2^u used when selecting discrete emissions intensity baseline\n",
    "        def TWO_U_RULE(model, u):\n",
    "            return float(2**u)\n",
    "        model.TWO_U = Param(model.OMEGA_U, rule=TWO_U_RULE)\n",
    "\n",
    "        # Binary variables used to determine discretized emissions intensity baseline choice\n",
    "        model.PSI = Var(model.OMEGA_U, within=Binary)\n",
    "\n",
    "        # Composite variable - PSI x tau - used to linearise bi-linear term\n",
    "        model.z_1 = Var(model.OMEGA_U)\n",
    "\n",
    "        # Big-M parameter used used to make z_1=0 when PSI=0, and z_1=tau when PSI=1\n",
    "        def L_1_RULE(model):\n",
    "            bound = 1e3\n",
    "            if use_pu:\n",
    "                return bound / model.BASE_POWER\n",
    "            else:\n",
    "                return bound\n",
    "        model.L_1 = Param(rule=L_1_RULE)\n",
    "\n",
    "        # Big-M paramter used to make z_2=0 when PSI=0, and z_2=p when PSI=1\n",
    "        def L_2_RULE(model, g):\n",
    "            return model.P_MAX[g] - model.P_MIN[g]\n",
    "        model.L_2 = Param(model.OMEGA_G, rule=L_2_RULE)\n",
    "\n",
    "        # Constraints such that z_1=0 when PSI=0 and z_1 = tau when PSI=1\n",
    "        def Z_1_CONSTRAINT_1_RULE(model, u):\n",
    "            return 0 <= model.tau - model.z_1[u]\n",
    "        model.Z_1_CONSTRAINT_1 = Constraint(model.OMEGA_U, rule=Z_1_CONSTRAINT_1_RULE)\n",
    "\n",
    "        def Z_1_CONSTRAINT_2_RULE(model, u):\n",
    "            return model.tau - model.z_1[u] <= model.L_1 * (1 - model.PSI[u])\n",
    "        model.Z_1_CONSTRAINT_2 = Constraint(model.OMEGA_U, rule=Z_1_CONSTRAINT_2_RULE)\n",
    "\n",
    "        def Z_1_CONSTRAINT_3_RULE(model, u):\n",
    "            return 0 <= model.z_1[u]\n",
    "        model.Z_1_CONSTRAINT_3 = Constraint(model.OMEGA_U, rule=Z_1_CONSTRAINT_3_RULE)\n",
    "\n",
    "        def Z_1_CONSTRAINT_4_RULE(model, u):\n",
    "            return model.z_1[u] <= model.L_1 * model.PSI[u]\n",
    "        model.Z_1_CONSTRAINT_4 = Constraint(model.OMEGA_U, rule=Z_1_CONSTRAINT_4_RULE)\n",
    "\n",
    "        # Discretised emissions intensity baseline value\n",
    "        model.PHI_DISCRETE = Expression(expr=model.PHI_MIN + (model.PHI_DELTA * sum(model.TWO_U[u] * model.PSI[u] for u in model.OMEGA_U)))\n",
    "\n",
    "\n",
    "    def SCENARIO_RULE(b, s):\n",
    "        \"Block of constraints describing optimality conditions for each scenario\"\n",
    "\n",
    "        # Parameters\n",
    "        # ----------       \n",
    "        # Fixed power injections\n",
    "        def R_RULE(b, n):\n",
    "            fixed_injection = float(model_data.df_scenarios.loc[('intermittent', n), s] + model_data.df_scenarios.loc[('hydro', n), s])\n",
    "            \n",
    "            # Remove very small fixed power injections to improve numerical conditioning\n",
    "            if fixed_injection < 1:\n",
    "                fixed_injection = 0\n",
    "            \n",
    "            if use_pu:\n",
    "                return fixed_injection / model.BASE_POWER\n",
    "            else:\n",
    "                return fixed_injection\n",
    "        b.R = Param(model.OMEGA_N, rule=R_RULE)\n",
    "\n",
    "        # Demand\n",
    "        def D_RULE(b, n):\n",
    "            demand = float(model_data.df_scenarios.loc[('demand', n), s])\n",
    "            \n",
    "            # Remove small demand to improve numerical conditioning\n",
    "            if demand < 1:\n",
    "                demand = 0\n",
    "                        \n",
    "            if use_pu:\n",
    "                return demand / model.BASE_POWER\n",
    "            else:\n",
    "                return demand\n",
    "        b.D = Param(model.OMEGA_N, rule=D_RULE)\n",
    "        \n",
    "        # Proportion of total demand consumed in each region\n",
    "        def ZETA_RULE(b, r):            \n",
    "            # Region demand\n",
    "            region_demand = float((model_data.df_scenarios.rename_axis(['level_1', 'NODE_ID'])\n",
    "                                   .join(model_data.df_n[['NEM_REGION']], how='left')\n",
    "                                   .reset_index()\n",
    "                                   .groupby(['NEM_REGION','level_1'])\n",
    "                                   .sum()\n",
    "                                   .loc[(r, 'demand'), s]))\n",
    "\n",
    "            # Total demand\n",
    "            total_demand = float(model_data.df_scenarios.reset_index().groupby('level_1').sum().loc['demand', s])\n",
    "            \n",
    "            # Proportion of demand consumed in region\n",
    "            demand_proportion = float(region_demand / total_demand)\n",
    "            \n",
    "            return demand_proportion\n",
    "        b.ZETA = Param(model.OMEGA_R, rule=ZETA_RULE)           \n",
    "\n",
    "        # Scenario duration\n",
    "        def RHO_RULE(b):\n",
    "            return float(model_data.df_scenarios.loc[('hours', 'duration'), s] / 8760)\n",
    "        b.RHO = Param(rule=RHO_RULE)\n",
    "\n",
    "\n",
    "        # Primal variables\n",
    "        # ----------------\n",
    "        # Generator output\n",
    "        b.p = Var(model.OMEGA_G)\n",
    "\n",
    "        # HVDC link flow\n",
    "        b.p_H = Var(model.OMEGA_H)\n",
    "\n",
    "        # Node voltage angle\n",
    "        b.theta = Var(model.OMEGA_N)\n",
    "\n",
    "\n",
    "        # Dual variables\n",
    "        # --------------\n",
    "        # Min power output constraint dual varaible\n",
    "        b.mu_1 = Var(model.OMEGA_G)\n",
    "\n",
    "        # Max power output constraint dual variable\n",
    "        b.mu_2 = Var(model.OMEGA_G)\n",
    "\n",
    "        # Max voltage angle difference constraint dual variable\n",
    "        b.mu_3 = Var(model.OMEGA_NM)\n",
    "\n",
    "        # AC link power flow constraint dual variable\n",
    "        b.mu_4 = Var(model.OMEGA_J)\n",
    "\n",
    "        # Min HVDC flow constraint dual variable\n",
    "        b.mu_5 = Var(model.OMEGA_H)\n",
    "\n",
    "        # Max HVDC flow constraint dual variable\n",
    "        b.mu_6 = Var(model.OMEGA_H)\n",
    "\n",
    "        # Reference node voltage angle constraint dual variable\n",
    "        b.nu_1 = Var(model.OMEGA_N)\n",
    "\n",
    "        # Node power balance constraint dual variable\n",
    "        b.lamb = Var(model.OMEGA_N)\n",
    "\n",
    "\n",
    "        # Binary variables\n",
    "        # ----------------\n",
    "        # Min power output binary variable\n",
    "        b.GAMMA_1 = Var(model.OMEGA_G, within=Binary)\n",
    "\n",
    "        # Max power output binary variable\n",
    "        b.GAMMA_2 = Var(model.OMEGA_G, within=Binary)\n",
    "\n",
    "        # Max voltage angle difference binary variable\n",
    "        b.GAMMA_3 = Var(model.OMEGA_NM, within=Binary)\n",
    "\n",
    "        # AC link power flow dual variable\n",
    "        b.GAMMA_4 = Var(model.OMEGA_J, within=Binary)\n",
    "\n",
    "        # Min HVDC flow binary variable\n",
    "        b.GAMMA_5 = Var(model.OMEGA_H, within=Binary)\n",
    "\n",
    "        # Max HVDC flow binary variable\n",
    "        b.GAMMA_6 = Var(model.OMEGA_H, within=Binary)\n",
    "\n",
    "        # Parameters and variables if emissions intensity baseline is variable\n",
    "        if variable_baseline:\n",
    "            # Composite variable - PSI x p - used to linearise bi-linear term\n",
    "            b.z_2 = Var(model.OMEGA_U * model.OMEGA_G)\n",
    "\n",
    "            # Constraints such that z_2=0 when PSI=0, and z_2=p when PSI=1\n",
    "            def Z_2_CONSTRAINT_1_RULE(b, u, g):\n",
    "                return 0 <= b.p[g] - b.z_2[u, g]\n",
    "            b.Z_2_CONSTRAINT_1 = Constraint(model.OMEGA_U * model.OMEGA_G, rule=Z_2_CONSTRAINT_1_RULE)\n",
    "\n",
    "            def Z_2_CONSTRAINT_2_RULE(b, u, g):\n",
    "                return b.p[g] - b.z_2[u, g] <= model.L_2[g] * (1 - model.PSI[u])\n",
    "            b.Z_2_CONSTRAINT_2 = Constraint(model.OMEGA_U * model.OMEGA_G, rule=Z_2_CONSTRAINT_2_RULE)\n",
    "\n",
    "            def Z_2_CONSTRAINT_3_RULE(b, u, g):\n",
    "                return 0 <= b.z_2[u, g]\n",
    "            b.Z_2_CONSTRAINT_3 = Constraint(model.OMEGA_U * model.OMEGA_G, rule=Z_2_CONSTRAINT_3_RULE)\n",
    "\n",
    "            def Z_2_CONSTRAINT_4_RULE(b, u, g):\n",
    "                return b.z_2[u, g] <= model.L_2[g] * model.PSI[u]\n",
    "            b.Z_2_CONSTRAINT_4 = Constraint(model.OMEGA_U * model.OMEGA_G, rule=Z_2_CONSTRAINT_4_RULE)\n",
    "\n",
    "\n",
    "        # Constraints\n",
    "        # -----------\n",
    "        # First order conditions\n",
    "        # If baseline is fixed\n",
    "        def FOC_1_RULE(b, g):\n",
    "            return (model.C[g] \n",
    "                    + ((model.E[g] - model.PHI) * model.tau) \n",
    "                    - b.mu_1[g] \n",
    "                    + b.mu_2[g] \n",
    "                    - b.lamb[f_1(g)] == 0)\n",
    "\n",
    "        # Linearised first order condition if baseline is variable\n",
    "        def FOC_1_LIN_RULE(b, g):\n",
    "            return (model.C[g] \n",
    "                    + ((model.E[g] - model.PHI_MIN) * model.tau) \n",
    "                    - (model.PHI_DELTA * sum(model.TWO_U[u] * model.z_1[u] for u in model.OMEGA_U)) \n",
    "                    - b.mu_1[g] + b.mu_2[g] - b.lamb[f_1(g)] == 0)\n",
    "\n",
    "        # Activate appropriate constraint depending on whether baseline is fixed or variable\n",
    "        if variable_baseline:\n",
    "            # Activate if variable\n",
    "            b.FOC_1_LIN = Constraint(model.OMEGA_G, rule=FOC_1_LIN_RULE)\n",
    "        else:\n",
    "            # Activate if fixed\n",
    "            b.FOC_1 = Constraint(model.OMEGA_G, rule=FOC_1_RULE)\n",
    "\n",
    "        def FOC_2_RULE(b, n):\n",
    "            return (sum(b.mu_3[n, m] \n",
    "                        - b.mu_3[m, n] \n",
    "                        + (b.lamb[n] * model.B[n, m]) \n",
    "                        - (b.lamb[m] * model.B[m, n]) for m in network_graph[n]) \n",
    "                    + (b.nu_1[n] * model.S_R[n]) \n",
    "                    + sum(model.B[ac_interconnector_branches.loc[l, 'BRANCH']] * b.mu_4[j] * model.S_L[n, l]\n",
    "                          for j in model.OMEGA_J for l in ac_interconnector_branch_ids.loc[j]\n",
    "                         ) == 0)\n",
    "        b.FOC_2 = Constraint(model.OMEGA_N, rule=FOC_2_RULE)\n",
    "\n",
    "        def FOC_3_RULE(b, h):\n",
    "            return ((model.K[f_2(h), h] * b.lamb[f_2(h)]) \n",
    "                    + (model.K[f_3(h), h] * b.lamb[f_3(h)]) \n",
    "                    - b.mu_5[h] \n",
    "                    + b.mu_6[h] == 0)\n",
    "        b.FOC_3 = Constraint(model.OMEGA_H, rule=FOC_3_RULE)\n",
    "\n",
    "        def EQUALITY_CONSTRAINT_1_RULE(b, n):\n",
    "            if model.S_R[n] == 1:\n",
    "                return b.theta[n] == 0\n",
    "            else:\n",
    "                return Constraint.Skip\n",
    "        b.EQUALITY_CONSTRAINT_1 = Constraint(model.OMEGA_N, rule=EQUALITY_CONSTRAINT_1_RULE)\n",
    "\n",
    "        def EQUALITY_CONSTRAINT_2_RULE(b, n):\n",
    "            return (b.D[n] \n",
    "                    - b.R[n] \n",
    "                    - sum(b.p[g] for g in generator_node_map[n]) \n",
    "                    + sum(model.B[n, m] * (b.theta[n] - b.theta[m]) for m in network_graph[n]) \n",
    "                    + sum(model.K[n, h] * b.p_H[h] for h in model.OMEGA_H) == 0)\n",
    "        b.EQUALITY_CONSTRAINT_2 = Constraint(model.OMEGA_N, rule=EQUALITY_CONSTRAINT_2_RULE)\n",
    "\n",
    "        # Linearised complementarity constraints\n",
    "        # --------------------------------------\n",
    "        # Min power output\n",
    "        def LIN_COMP_1_1_RULE(b, g):\n",
    "            return model.P_MIN[g] - b.p[g] <= 0\n",
    "        b.LIN_COMP_1_1 = Constraint(model.OMEGA_G, rule=LIN_COMP_1_1_RULE)\n",
    "\n",
    "        def LIN_COMP_1_2_RULE(b, g):\n",
    "            return b.mu_1[g] >= 0\n",
    "        b.LIN_COMP_1_2 = Constraint(model.OMEGA_G, rule=LIN_COMP_1_2_RULE)\n",
    "\n",
    "        def LIN_COMP_1_3_RULE(b, g):\n",
    "            return b.p[g] - model.P_MIN[g] <= b.GAMMA_1[g] * model.M_11[g]\n",
    "        b.LIN_COMP_1_3 = Constraint(model.OMEGA_G, rule=LIN_COMP_1_3_RULE)\n",
    "\n",
    "        def LIN_COMP_1_4_RULE(b, g):\n",
    "            return b.mu_1[g] <= (1 - b.GAMMA_1[g]) * model.M_12[g]\n",
    "        b.LIN_COMP_1_4 = Constraint(model.OMEGA_G, rule=LIN_COMP_1_4_RULE)\n",
    "\n",
    "        # Max power output\n",
    "        def LIN_COMP_2_1_RULE(b, g):\n",
    "            return b.p[g] - model.P_MAX[g] <= 0\n",
    "        b.LIN_COMP_2_1 = Constraint(model.OMEGA_G, rule=LIN_COMP_2_1_RULE)\n",
    "\n",
    "        def LIN_COMP_2_2_RULE(b, g):\n",
    "            return b.mu_2[g] >= 0\n",
    "        b.LIN_COMP_2_2 = Constraint(model.OMEGA_G, rule=LIN_COMP_2_2_RULE)\n",
    "\n",
    "        def LIN_COMP_2_3_RULE(b, g):\n",
    "            return model.P_MAX[g] - b.p[g] <= b.GAMMA_2[g] * model.M_21[g]\n",
    "        b.LIN_COMP_2_3 = Constraint(model.OMEGA_G, rule=LIN_COMP_2_3_RULE)\n",
    "\n",
    "        def LIN_COMP_2_4_RULE(b, g):\n",
    "            return b.mu_2[g] <= (1 - b.GAMMA_2[g]) * model.M_22[g]\n",
    "        b.LIN_COMP_2_4 = Constraint(model.OMEGA_G, rule=LIN_COMP_2_4_RULE)\n",
    "\n",
    "        # Max voltage angle difference between connected nodes\n",
    "        def LIN_COMP_3_1_RULE(b, n, m):\n",
    "            return b.theta[n] - b.theta[m] - model.THETA_DELTA <= 0\n",
    "        b.LIN_COMP_3_1 = Constraint(model.OMEGA_NM, rule=LIN_COMP_3_1_RULE)\n",
    "\n",
    "        def LIN_COMP_3_2_RULE(b, n, m):\n",
    "            return b.mu_3[n, m] >= 0\n",
    "        b.LIN_COMP_3_2 = Constraint(model.OMEGA_NM, rule=LIN_COMP_3_2_RULE)\n",
    "\n",
    "        def LIN_COMP_3_3_RULE(b, n, m):\n",
    "            return model.THETA_DELTA + b.theta[m] - b.theta[n] <= b.GAMMA_3[n, m] * model.M_31[n, m]\n",
    "        b.LIN_COMP_3_3 = Constraint(model.OMEGA_NM, rule=LIN_COMP_3_3_RULE)\n",
    "\n",
    "        def LIN_COMP_3_4_RULE(b, n, m):\n",
    "            return b.mu_3[n, m] <= (1 - b.GAMMA_3[n, m]) * model.M_32[n, m]\n",
    "        b.LIN_COMP_3_4 = Constraint(model.OMEGA_NM, rule=LIN_COMP_3_4_RULE)\n",
    "\n",
    "        # Interconnector flow limits\n",
    "        def LIN_COMP_4_1_RULE(b, j):\n",
    "            branches = [ac_interconnector_branches.loc[branch_id, 'BRANCH'] for branch_id in ac_interconnector_branch_ids.loc[j]]\n",
    "            return sum(model.B[n, m] * (b.theta[n] - b.theta[m]) for n, m in branches) - model.F[j] <= 0\n",
    "        b.LIN_COMP_4_1 = Constraint(model.OMEGA_J, rule=LIN_COMP_4_1_RULE)\n",
    "\n",
    "        def LIN_COMP_4_2_RULE(b, j):\n",
    "            return b.mu_4[j] >= 0\n",
    "        b.LIN_COMP_4_2 = Constraint(model.OMEGA_J, rule=LIN_COMP_4_2_RULE)\n",
    "\n",
    "        def LIN_COMP_4_3_RULE(b, j):\n",
    "            branches = [ac_interconnector_branches.loc[branch_id, 'BRANCH'] for branch_id in ac_interconnector_branch_ids.loc[j]]\n",
    "            return model.F[j] - sum(model.B[n, m] * (b.theta[n] - b.theta[m]) for n, m in branches) <= b.GAMMA_4[j] * model.M_41[j]\n",
    "        b.LIN_COMP_4_3 = Constraint(model.OMEGA_J, rule=LIN_COMP_4_3_RULE)\n",
    "\n",
    "        def LIN_COMP_4_4_RULE(b, j):\n",
    "            return b.mu_4[j] <= (1 - b.GAMMA_4[j]) * model.M_42[j]\n",
    "        b.LIN_COMP_4_4 = Constraint(model.OMEGA_J, rule=LIN_COMP_4_4_RULE)\n",
    "\n",
    "        # HVDC link flow limits\n",
    "        def LIN_COMP_5_1_RULE(b, h):\n",
    "            return model.P_H_MIN[h] - b.p_H[h] <= 0\n",
    "        b.LIN_COMP_5_1 = Constraint(model.OMEGA_H, rule=LIN_COMP_5_1_RULE)\n",
    "\n",
    "        def LIN_COMP_5_2_RULE(b, h):\n",
    "            return b.mu_5[h] >= 0\n",
    "        b.LIN_COMP_5_2 = Constraint(model.OMEGA_H, rule=LIN_COMP_5_2_RULE)\n",
    "\n",
    "        def LIN_COMP_5_3_RULE(b, h):\n",
    "            return b.p_H[h] - model.P_H_MIN[h] <= b.GAMMA_5[h] * model.M_51[h]\n",
    "        b.LIN_COMP_5_3 = Constraint(model.OMEGA_H, rule=LIN_COMP_5_3_RULE)\n",
    "\n",
    "        def LIN_COMP_5_4_RULE(b, h):\n",
    "            return b.mu_5[h] <= (1 - b.GAMMA_5[h]) * model.M_52[h]\n",
    "        b.LIN_COMP_5_4 = Constraint(model.OMEGA_H, rule=LIN_COMP_5_4_RULE)\n",
    "\n",
    "        def LIN_COMP_6_1_RULE(b, h):\n",
    "            return b.p_H[h] - model.P_H_MAX[h] <= 0\n",
    "        b.LIN_COMP_6_1 = Constraint(model.OMEGA_H, rule=LIN_COMP_6_1_RULE)\n",
    "\n",
    "        def LIN_COMP_6_2_RULE(b, h):\n",
    "            return b.mu_6[h] >= 0\n",
    "        b.LIN_COMP_6_2 = Constraint(model.OMEGA_H, rule=LIN_COMP_6_2_RULE)\n",
    "\n",
    "        def LIN_COMP_6_3_RULE(b, h):\n",
    "            return model.P_H_MAX[h] - b.p_H[h] <= b.GAMMA_6[h] * model.M_61[h]\n",
    "        b.LIN_COMP_6_3 = Constraint(model.OMEGA_H, rule=LIN_COMP_6_3_RULE)\n",
    "\n",
    "        def LIN_COMP_6_4_RULE(b, h):\n",
    "            return b.mu_6[h] <= (1 - b.GAMMA_6[h]) * model.M_62[h]\n",
    "        b.LIN_COMP_6_4 = Constraint(model.OMEGA_H, rule=LIN_COMP_6_4_RULE)\n",
    "    model.SCENARIO = Block(model.OMEGA_S, rule=SCENARIO_RULE)\n",
    "\n",
    "    # Permit market complementarity constraints\n",
    "    def PERMIT_MARKET_1_RULE(model):\n",
    "        return sum(model.SCENARIO[s].RHO * ((model.E[g] - model.PHI) * model.SCENARIO[s].p[g]) for g in model.OMEGA_G for s in model.OMEGA_S) <= 0\n",
    "\n",
    "    def PERMIT_MARKET_1_LIN_RULE(model):\n",
    "        return (sum(model.SCENARIO[s].RHO * (((model.E[g] - model.PHI_MIN) * model.SCENARIO[s].p[g]) \n",
    "                                            - (model.PHI_DELTA * sum(model.TWO_U[u] * model.SCENARIO[s].z_2[u, g] for u in model.OMEGA_U))) for g in model.OMEGA_G for s in model.OMEGA_S) <= 0)\n",
    "\n",
    "    def PERMIT_MARKET_2_RULE(model):\n",
    "        return model.tau >= 0\n",
    "    model.PERMIT_MARKET_2 = Constraint(rule=PERMIT_MARKET_2_RULE)\n",
    "\n",
    "    def PERMIT_MARKET_3_RULE(model):\n",
    "        return sum(model.SCENARIO[s].RHO * ((model.PHI - model.E[g]) * model.SCENARIO[s].p[g]) for g in model.OMEGA_G for s in model.OMEGA_S) <= model.GAMMA_7 * model.M_71\n",
    "\n",
    "    def PERMIT_MARKET_3_LIN_RULE(model):\n",
    "        return (sum(model.SCENARIO[s].RHO * (((model.PHI_MIN - model.E[g]) * model.SCENARIO[s].p[g]) \n",
    "                                            + (model.PHI_DELTA * sum(model.TWO_U[u] * model.SCENARIO[s].z_2[u, g] for u in model.OMEGA_U))) for g in model.OMEGA_G for s in model.OMEGA_S) <= model.GAMMA_7 * model.M_71)\n",
    "\n",
    "    def PERMIT_MARKET_4_RULE(model):\n",
    "        return model.tau <= (1 - model.GAMMA_7) * model.M_72\n",
    "    model.PERMIT_MARKET_4 = Constraint(rule=PERMIT_MARKET_4_RULE)\n",
    "\n",
    "    # Use appropriate constraint formulations depending on whether emissions intensity baseline is variable or not\n",
    "    if variable_baseline:\n",
    "        model.PERMIT_MARKET_1_LIN = Constraint(rule=PERMIT_MARKET_1_LIN_RULE)\n",
    "        model.PERMIT_MARKET_3_LIN = Constraint(rule=PERMIT_MARKET_3_LIN_RULE)\n",
    "    else:\n",
    "        model.PERMIT_MARKET_1 = Constraint(rule=PERMIT_MARKET_1_RULE)\n",
    "        model.PERMIT_MARKET_3 = Constraint(rule=PERMIT_MARKET_3_RULE)\n",
    "\n",
    "\n",
    "    # Expressions\n",
    "    # -----------\n",
    "    # Total revenue from electricity sales\n",
    "    model.TOTAL_REVENUE = Expression(expr=sum(model.SCENARIO[s].RHO * model.SCENARIO[s].lamb[n] * model.SCENARIO[s].D[n] for s in model.OMEGA_S for n in model.OMEGA_N))\n",
    "\n",
    "    # Total demand\n",
    "    model.TOTAL_DEMAND = Expression(expr=sum(model.SCENARIO[s].RHO * model.SCENARIO[s].D[n] for s in model.OMEGA_S for n in model.OMEGA_N))\n",
    "\n",
    "    # Average price\n",
    "    model.AVERAGE_ELECTRICITY_PRICE = Expression(expr=model.TOTAL_REVENUE / model.TOTAL_DEMAND)\n",
    "\n",
    "    # Weighted RRN price\n",
    "    model.WEIGHTED_RRN_PRICE = Expression(expr=sum(model.SCENARIO[s].RHO * model.SCENARIO[s].ZETA[r] * model.SCENARIO[s].lamb[f_4(r)] for s in model.OMEGA_S for r in model.OMEGA_R))\n",
    "\n",
    "\n",
    "    # Objective functions\n",
    "    # -------------------\n",
    "    # Feasibility\n",
    "    if objective_type == 'feasibility':\n",
    "        model.dummy = Var(bounds=(0, 1))\n",
    "        model.OBJECTIVE = Objective(expr=model.dummy, sense=minimize)\n",
    "        \n",
    "        \n",
    "    # Permit price target\n",
    "    elif objective_type == 'permit_price_target':\n",
    "        \n",
    "        def PERMIT_PRICE_TARGET_RULE(model):\n",
    "            # Permit price target [$/tCO2]\n",
    "            permit_price_target = 30\n",
    "            \n",
    "            if use_pu:\n",
    "                return permit_price_target / model.BASE_POWER\n",
    "            else:\n",
    "                return permit_price_target\n",
    "        model.PERMIT_PRICE_TARGET = Param(initialize=PERMIT_PRICE_TARGET_RULE, mutable=True)\n",
    "        \n",
    "        # Dummy variables used to target given permit price\n",
    "        model.PERMIT_PRICE_TARGET_X_1 = Var(within=NonNegativeReals)\n",
    "        model.PERMIT_PRICE_TARGET_X_2 = Var(within=NonNegativeReals)\n",
    "        \n",
    "        # Constraints to minimise difference between permit price and target\n",
    "        model.PERMIT_PRICE_TARGET_CONSTRAINT_1 = Constraint(expr=model.PERMIT_PRICE_TARGET_X_1 >= model.PERMIT_PRICE_TARGET - model.tau)\n",
    "        model.PERMIT_PRICE_TARGET_CONSTRAINT_2 = Constraint(expr=model.PERMIT_PRICE_TARGET_X_2 >= model.tau - model.PERMIT_PRICE_TARGET)\n",
    "        \n",
    "        # Objective function\n",
    "        model.OBJECTIVE = Objective(expr=model.PERMIT_PRICE_TARGET_X_1 + model.PERMIT_PRICE_TARGET_X_2)\n",
    "        \n",
    "        \n",
    "    # Weighted RRN price target        \n",
    "    elif objective_type == 'weighted_rrn_price_target':\n",
    "        # Weighted RRN price target\n",
    "        def WEIGHTED_RRN_PRICE_TARGET_RULE(model):\n",
    "            # Price target [$/MWh]\n",
    "            weighted_rrn_price_target = 36\n",
    "\n",
    "            if use_pu:\n",
    "                return weighted_rrn_price_target / model.BASE_POWER\n",
    "            else:\n",
    "                return weighted_rrn_price_target\n",
    "        model.WEIGHTED_RRN_PRICE_TARGET = Param(initialize=WEIGHTED_RRN_PRICE_TARGET_RULE, mutable=True)\n",
    "        \n",
    "        # Dummy variables used to minimise difference between average price and price target\n",
    "        model.WEIGHTED_RRN_PRICE_X_1 = Var(within=NonNegativeReals)\n",
    "        model.WEIGHTED_RRN_PRICE_X_2 = Var(within=NonNegativeReals)\n",
    "        \n",
    "        # Constraints used to minimise difference between RRN price target and RRN price\n",
    "        model.WEIGHTED_RRN_PRICE_TARGET_CONSTRAINT_1 = Constraint(expr=model.WEIGHTED_RRN_PRICE_X_1 >= model.WEIGHTED_RRN_PRICE - model.WEIGHTED_RRN_PRICE_TARGET)\n",
    "        model.WEIGHTED_RRN_PRICE_TARGET_CONSTRAINT_2 = Constraint(expr=model.WEIGHTED_RRN_PRICE_X_2 >= model.WEIGHTED_RRN_PRICE_TARGET - model.WEIGHTED_RRN_PRICE)\n",
    "        \n",
    "        # Weighted RRN price targeting objective function\n",
    "        model.OBJECTIVE = Objective(expr=model.WEIGHTED_RRN_PRICE_X_1 + model.WEIGHTED_RRN_PRICE_X_2)\n",
    "        \n",
    "        \n",
    "    # Nodal electricity price target\n",
    "    elif objective_type == 'nodal_electricity_price_target':\n",
    "        def NODAL_ELECTRICITY_PRICE_TARGET_RULE(model, s, n):\n",
    "            # Price target [$/MWh]\n",
    "            target_nodal_price = 30\n",
    "            \n",
    "            if use_pu:\n",
    "                return target_nodal_price / model.BASE_POWER\n",
    "            else:\n",
    "                return target_nodal_price\n",
    "        model.NODAL_ELECTRICITY_PRICE_TARGET = Param(model.OMEGA_S, model.OMEGA_N, initialize=NODAL_ELECTRICITY_PRICE_TARGET_RULE, mutable=True)\n",
    "        \n",
    "        # Dummy variables used to minimise difference between nodal price and target\n",
    "        model.NODAL_ELECTRICITY_PRICE_X_1 = Var(model.OMEGA_S, model.OMEGA_N, within=NonNegativeReals)\n",
    "        model.NODAL_ELECTRICITY_PRICE_X_2 = Var(model.OMEGA_S, model.OMEGA_N, within=NonNegativeReals)\n",
    "        \n",
    "        # Constraints to minimise difference between nodal price and target\n",
    "        def NODAL_ELECTRICTY_PRICE_TARGET_CONSTRAINT_1_RULE(model, s, n):\n",
    "            return model.NODAL_ELECTRICITY_PRICE_X_1[s, n] >= model.SCENARIO[s].lamb[n] - model.NODAL_ELECTRICITY_PRICE_TARGET[s, n]\n",
    "        model.NODAL_ELECTRICTY_PRICE_TARGET_CONSTRAINT_1 = Constraint(model.OMEGA_S, model.OMEGA_N, rule=NODAL_ELECTRICTY_PRICE_TARGET_CONSTRAINT_1_RULE)\n",
    "\n",
    "        def NODAL_ELECTRICTY_PRICE_TARGET_CONSTRAINT_2_RULE(model, s, n):\n",
    "            return model.NODAL_ELECTRICITY_PRICE_X_2[s, n] >= model.NODAL_ELECTRICITY_PRICE_TARGET[s, n] -  model.SCENARIO[s].lamb[n]\n",
    "        model.NODAL_ELECTRICTY_PRICE_TARGET_CONSTRAINT_2 = Constraint(model.OMEGA_S, model.OMEGA_N, rule=NODAL_ELECTRICTY_PRICE_TARGET_CONSTRAINT_2_RULE)\n",
    "\n",
    "        # Nodal price objective\n",
    "        model.OBJECTIVE = Objective(expr=sum(model.SCENARIO[s].RHO * model.SCENARIO[s].D[n] * (model.NODAL_ELECTRICITY_PRICE_X_1[s, n] + model.NODAL_ELECTRICITY_PRICE_X_2[s, n]) for s in model.OMEGA_S for n in model.OMEGA_N))\n",
    "        \n",
    "        \n",
    "    # Minimise average electricity price  \n",
    "    elif objective_type == 'minimise_electricity_price':\n",
    "        model.OBJECTIVE = Objective(expr=model.AVERAGE_ELECTRICITY_PRICE, sense=minimize)\n",
    "        \n",
    "        # Add constraint to put a lower-bound on the average electricity price (help solver)\n",
    "        model.AVERAGE_PRICE_MIN = Param(initialize=0.3, mutable=True)\n",
    "        model.AVERAGE_PRICE_LOWER_BOUND = Constraint(expr=model.AVERAGE_ELECTRICITY_PRICE >= model.AVERAGE_PRICE_MIN)\n",
    "\n",
    "    else:\n",
    "        raise(Exception('Invalid objective type'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup solver\n",
    "# ------------\n",
    "solver = 'cplex'\n",
    "solver_io = 'mps'\n",
    "opt = SolverFactory(solver, solver_io=solver_io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check model runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Initializing ordered Set OMEGA_NM with a fundamentally unordered data\n",
      "    source (type: set).  This WILL potentially lead to nondeterministic\n",
      "    behavior in Pyomo\n",
      "Flow directions conform with regional flow limit directions: True\n",
      "Flow directions conform with regional flow limit directions: True\n",
      "Flow directions conform with regional flow limit directions: True\n",
      "\n",
      "Welcome to IBM(R) ILOG(R) CPLEX(R) Interactive Optimizer 12.10.0.0\n",
      "  with Simplex, Mixed Integer & Barrier Optimizers\n",
      "5725-A06 5725-A29 5724-Y48 5724-Y49 5724-Y54 5724-Y55 5655-Y21\n",
      "Copyright IBM Corp. 1988, 2019.  All Rights Reserved.\n",
      "\n",
      "Type 'help' for a list of available commands.\n",
      "Type 'help' followed by a command name for more\n",
      "information on commands.\n",
      "\n",
      "CPLEX> Logfile 'cplex.log' closed.\n",
      "Logfile '/tmp/tmpvrln9ca2.cplex.log' open.\n",
      "CPLEX> Specified objective sense: MINIMIZE\n",
      "Selected objective  name:  x16566\n",
      "Selected RHS        name:  RHS\n",
      "Selected bound      name:  BOUND\n",
      "Problem '/tmp/tmpnvbh9q45.pyomo.mps' read.\n",
      "Read time = 0.03 sec. (6.28 ticks)\n",
      "CPLEX> Warning: no MIP start values read, no MIP start loaded.\n",
      "MIP start file '/tmp/tmpgqm_8bv3.cplex.mst' read.\n",
      "CPLEX> Problem name         : /tmp/tmpnvbh9q45.pyomo.mps\n",
      "Objective sense      : Minimize\n",
      "Variables            :   14745  [Box: 1,  Free: 9335,  Binary: 5409]\n",
      "Objective nonzeros   :       1\n",
      "Linear constraints   :   25562  [Less: 16227,  Greater: 5409,  Equal: 3926]\n",
      "  Nonzeros           :   67220\n",
      "  RHS nonzeros       :   17522\n",
      "\n",
      "Variables            : Min LB: 0.000000         Max UB: 1.000000       \n",
      "Objective nonzeros   : Min   : 1.000000         Max   : 1.000000       \n",
      "Linear constraints   :\n",
      "  Nonzeros           : Min   : 0.001862317      Max   : 83215.16       \n",
      "  RHS nonzeros       : Min   : 0.0001685220     Max   : 100.0000       \n",
      "CPLEX> Version identifier: 12.10.0.0 | 2019-11-26 | 843d4de\n",
      "Warning:  No solution found from 1 MIP starts.\n",
      "Retaining values of one MIP start for possible repair.\n",
      "Tried aggregator 7 times.\n",
      "MIP Presolve eliminated 16360 rows and 5549 columns.\n",
      "MIP Presolve modified 5455 coefficients.\n",
      "Aggregator did 2208 substitutions.\n",
      "Reduced MIP has 6994 rows, 6988 columns, and 24731 nonzeros.\n",
      "Reduced MIP has 2958 binaries, 0 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.48 sec. (353.95 ticks)\n",
      "Probing fixed 2231 vars, tightened 5787 bounds.\n",
      "Probing time = 2.84 sec. (1814.73 ticks)\n",
      "Tried aggregator 4 times.\n",
      "MIP Presolve eliminated 3377 rows and 4472 columns.\n",
      "MIP Presolve modified 2147 coefficients.\n",
      "Aggregator did 292 substitutions.\n",
      "Reduced MIP has 3325 rows, 2224 columns, and 10212 nonzeros.\n",
      "Reduced MIP has 726 binaries, 0 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.03 sec. (27.96 ticks)\n",
      "Probing fixed 23 vars, tightened 865 bounds.\n",
      "Probing time = 0.19 sec. (136.18 ticks)\n",
      "Tried aggregator 2 times.\n",
      "Detecting symmetries...\n",
      "MIP Presolve eliminated 27 rows and 46 columns.\n",
      "MIP Presolve modified 180 coefficients.\n",
      "Aggregator did 4 substitutions.\n",
      "Reduced MIP has 3294 rows, 2174 columns, and 9791 nonzeros.\n",
      "Reduced MIP has 703 binaries, 0 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.01 sec. (8.60 ticks)\n",
      "Probing fixed 5 vars, tightened 2103 bounds.\n",
      "Probing time = 0.26 sec. (210.91 ticks)\n",
      "Clique table members: 3595.\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: dynamic search.\n",
      "Parallel mode: deterministic, using up to 4 threads.\n",
      "Root relaxation solution time = 0.13 sec. (129.64 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap\n",
      "\n",
      "      0     0        0.0000   194                      0.0000     1375         \n",
      "      0     0        0.0000   194                   Cuts: 131     1430         \n",
      "      0     0        0.0000   194                   Cuts: 114     1493         \n",
      "      0     0        0.0000   194                    Cuts: 78     1551         \n",
      "      0     0        0.0000   194                    Cuts: 25     1573         \n",
      "      0     0        0.0000   194                     Cuts: 8     1577         \n",
      "Detecting symmetries...\n",
      "Repair heuristic found nothing.\n",
      "Detecting symmetries...\n",
      "      0     2        0.0000    95                      0.0000     1577         \n",
      "Elapsed time = 18.42 sec. (13503.56 ticks, tree = 0.02 MB, solutions = 0)\n",
      "     82    25        0.0000    64                      0.0000     6124         \n",
      "    238    93        0.0000    14                      0.0000    12709         \n",
      "    282    93        0.0000    39                      0.0000    15157         \n",
      "    502   136    infeasible                            0.0000    18742         \n",
      "    750   168        0.0000    24                      0.0000    23763         \n",
      "    959   195    infeasible                            0.0000    28423         \n",
      "   1210   149    infeasible                            0.0000    33767         \n",
      "   1510   182    infeasible                            0.0000    40650         \n",
      "   1912   138        0.0000    46                      0.0000    47416         \n",
      "   3193   210        0.0000    41                      0.0000    75970         \n",
      "Elapsed time = 22.00 sec. (16760.81 ticks, tree = 0.17 MB, solutions = 0)\n",
      "   3795   234        0.0000     7                      0.0000    90494         \n",
      "*  4173   209      integral     0        0.0000        0.0000    93787    0.00%\n",
      "\n",
      "Clique cuts applied:  21\n",
      "Cover cuts applied:  15\n",
      "Implied bound cuts applied:  82\n",
      "Flow cuts applied:  61\n",
      "Mixed integer rounding cuts applied:  74\n",
      "Gomory fractional cuts applied:  8\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =   18.39 sec. (13480.68 ticks)\n",
      "Parallel b&c, 4 threads:\n",
      "  Real time             =    5.19 sec. (4560.95 ticks)\n",
      "  Sync time (average)   =    0.54 sec.\n",
      "  Wait time (average)   =    0.00 sec.\n",
      "                          ------------\n",
      "Total (root+branch&cut) =   23.59 sec. (18041.63 ticks)\n",
      "\n",
      "Solution pool: 1 solution saved.\n",
      "\n",
      "MIP - Integer optimal solution:  Objective =  0.0000000000e+00\n",
      "Solution time =   23.59 sec.  Iterations = 99837  Nodes = 4268\n",
      "Deterministic time = 18041.67 ticks  (764.87 ticks/sec)\n",
      "\n",
      "CPLEX> Incumbent solution written to file '/tmp/tmpb4hpm59h.cplex.sol'.\n",
      "CPLEX> "
     ]
    }
   ],
   "source": [
    "# Run BAU model (very high baseline)\n",
    "model_bau = create_model(use_pu=True, variable_baseline=False, objective_type='feasibility')\n",
    "model_bau.PHI = 1.5\n",
    "res_bau = opt.solve(model_bau, keepfiles=False, tee=True, warmstart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check if case should be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_processed(filename, overwrite=True):\n",
    "    \"\"\"Check if file has been processed\"\"\"\n",
    "    \n",
    "    # Files that have already been processed\n",
    "    files = os.listdir(paths.output_dir)\n",
    "    \n",
    "    if (filename in files) and not overwrite:\n",
    "        # No need to process file\n",
    "        return False\n",
    "    else:\n",
    "        # Need to process the file\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve model for different emissions intensity baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_emissions_intensity_baseline_scenarios():\n",
    "    \"Run model for different emissions intensity baseline scenarios\"\n",
    "    \n",
    "    # Instantiate model object\n",
    "    model = create_model(use_pu=True, variable_baseline=False, objective_type='feasibility')\n",
    "    opt.options['mip tolerances absmipgap'] = 1e-6\n",
    "    opt.options['emphasis mip'] = 1 # Emphasise feasibility\n",
    "\n",
    "    # Voltage angle difference limits\n",
    "    for angle_limit in [pi/2, pi/3]:\n",
    "#     for angle_limit in [pi/2]:\n",
    "        \n",
    "        # Update voltage angle difference limit\n",
    "        model.THETA_DELTA = angle_limit\n",
    "        \n",
    "        # Solve model for different PHI scenarios\n",
    "        for baseline in np.linspace(1.1, 0.9, 41):\n",
    "#         for baseline in [1.1]:        \n",
    "\n",
    "            # Dictionary in which to store results\n",
    "            fixed_baseline_results = dict()\n",
    "\n",
    "            # Update baseline\n",
    "            print('Emissions intensity baseline: {0} tCO2/MWh'.format(baseline))\n",
    "            model.PHI = baseline\n",
    "            \n",
    "            # Filename corresponding to case\n",
    "            filename = f'fixed_baseline_results_phi_{model.PHI.value:.3f}_angle_limit_{angle_limit:.3f}.pickle'            \n",
    "            \n",
    "            # Check if case should be processed\n",
    "            process_case = check_processed(filename, overwrite=False)\n",
    "            if process_case:\n",
    "                pass\n",
    "            else:\n",
    "                print(f'Already processed. Skipping: {filename}')\n",
    "                continue\n",
    "\n",
    "            # Model results\n",
    "            res = opt.solve(model, keepfiles=False, tee=True, warmstart=True)\n",
    "            model.solutions.store_to(res)\n",
    "\n",
    "            # Place results in DataFrame\n",
    "            try:\n",
    "                df = pd.DataFrame(res['Solution'][0])\n",
    "                fixed_baseline_results = {'FIXED_BASELINE': model.PHI.value, 'results': df}\n",
    "            except:\n",
    "                fixed_baseline_results = {'FIXED_BASELINE': model.PHI.value, 'results': 'infeasible'}\n",
    "                print('Baseline {0} is infeasible'.format(model.PHI.value))   \n",
    "\n",
    "            # Try to print results\n",
    "            try:\n",
    "                print(model.AVERAGE_ELECTRICITY_PRICE.display())\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                print(model.tau.display())\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # Save results\n",
    "            with open(os.path.join(paths.output_dir, filename), 'wb') as f:\n",
    "                pickle.dump(fixed_baseline_results, f)\n",
    "            \n",
    "run_emissions_intensity_baseline_scenarios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify baseline that targets wholesale electricity price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_weighted_rrn_price_target_scenarios():\n",
    "    \"Run model that targets weighted RRN electricity prices\"\n",
    "    \n",
    "    # Run BAU model (very high baseline)\n",
    "    model_bau = create_model(use_pu=True, variable_baseline=False, objective_type='feasibility')\n",
    "    model_bau.PHI = 1.5\n",
    "       \n",
    "    # Instantiate model object\n",
    "    model = create_model(use_pu=True, variable_baseline=True, objective_type='weighted_rrn_price_target')\n",
    "    opt.options['mip tolerances absmipgap'] = 1e-3\n",
    "\n",
    "    # Voltage angle difference limits\n",
    "    for angle_limit in [pi/2, pi/3]:\n",
    "#     for angle_limit in [pi/2]:\n",
    "\n",
    "        # Update voltage angle difference limit\n",
    "        model_bau.THETA_DELTA = angle_limit\n",
    "        model.THETA_DELTA = angle_limit\n",
    "        \n",
    "        # BAU model results\n",
    "        print('Solving BAU scenario')\n",
    "        res_bau = opt.solve(model_bau, keepfiles=False, tee=True, warmstart=True)    \n",
    "        model_bau.solutions.store_to(res_bau)\n",
    "        bau_weighted_rnn_price = model_bau.WEIGHTED_RRN_PRICE.expr()\n",
    "        print('BAU weighted RNN price: {0}'.format(bau_weighted_rnn_price))\n",
    "        \n",
    "        # Update voltage angle difference limit\n",
    "        model.THETA_DELTA = angle_limit\n",
    "    \n",
    "        # Weighted RNN price target as a multiple of BAU weighted RNN price\n",
    "        for price_multiplier in [1.1, 1.2, 1.3, 1.4, 0.8]:\n",
    "#         for price_multiplier in [1.1]:\n",
    "        \n",
    "            # Filename corresponding to case\n",
    "            filename = f'weighted_rrn_price_target_{price_multiplier:.3f}_angle_limit_{angle_limit:.3f}.pickle'\n",
    "        \n",
    "            # Check if case should be processed\n",
    "            process_case = check_processed(filename, overwrite=False)\n",
    "            if process_case:\n",
    "                pass\n",
    "            else:\n",
    "                print(f'Already processed. Skipping: {filename}')\n",
    "                continue\n",
    "        \n",
    "        \n",
    "            # Update price target\n",
    "            model.WEIGHTED_RRN_PRICE_TARGET = price_multiplier * bau_weighted_rnn_price\n",
    "            print('Target price input: {}'.format(price_multiplier * bau_weighted_rnn_price))\n",
    "\n",
    "            # Model results\n",
    "            res = opt.solve(model, keepfiles=False, tee=True, warmstart=True)\n",
    "            model.solutions.store_to(res)\n",
    "\n",
    "            # Place results in DataFrame\n",
    "            try:\n",
    "                df = pd.DataFrame(res['Solution'][0])\n",
    "                price_target_results = {'WEIGHTED_RRN_PRICE_TARGET': model.WEIGHTED_RRN_PRICE_TARGET.value,\n",
    "                                        'WEIGHTED_RRN_PRICE_TARGET_BAU_MULTIPLE': price_multiplier,\n",
    "                                        'results': df,\n",
    "                                        'PHI_DISCRETE': model.PHI_DISCRETE.expr()}\n",
    "            except:\n",
    "                price_target_results = {'WEIGHTED_RRN_PRICE_TARGET': model.WEIGHTED_RRN_PRICE_TARGET.value,\n",
    "                                        'results': 'infeasible'}\n",
    "                print('Weighted RNN price target {0} is infeasible'.format(model.WEIGHTED_RRN_PRICE_TARGET.value))   \n",
    "\n",
    "            # Try to print results\n",
    "            try:\n",
    "                print(model.WEIGHTED_RRN_PRICE.display())\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                print(model.PHI_DISCRETE.display())\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            print(model.tau.display())\n",
    "\n",
    "            # Save results\n",
    "            with open(os.path.join(paths.output_dir, filename), 'wb') as f:\n",
    "                pickle.dump(price_target_results, f)\n",
    "           \n",
    "run_weighted_rrn_price_target_scenarios()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify baseline that targets equilibrium permit price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_permit_price_target_scenarios():\n",
    "    \"Run model for different permit price target scenarios\"\n",
    "\n",
    "    # Instantiate model object\n",
    "    model = create_model(use_pu=True, variable_baseline=True, objective_type='permit_price_target')\n",
    "    opt.options['mip tolerances absmipgap'] = 1e-3\n",
    "\n",
    "    # Voltage angle difference limits\n",
    "    for angle_limit in [pi/2, pi/3]:\n",
    "#     for angle_limit in [pi/2]:\n",
    "        \n",
    "        # Update voltage angle difference limit\n",
    "        model.THETA_DELTA = angle_limit\n",
    "        \n",
    "        for permit_price in [25/100, 50/100, 75/100, 100/100]:\n",
    "#         for permit_price in [25/100]:\n",
    "        \n",
    "            # Filename\n",
    "            filename = f'permit_price_target_{permit_price:.3f}_angle_limit_{angle_limit:.3f}.pickle'\n",
    "\n",
    "            # Check if case should be processed\n",
    "            process_case = check_processed(filename, overwrite=False)\n",
    "            if process_case:\n",
    "                pass\n",
    "            else:\n",
    "                print(f'Already processed. Skipping: {filename}')\n",
    "                continue\n",
    "        \n",
    "        \n",
    "            # Set permit price target\n",
    "            model.PERMIT_PRICE_TARGET = permit_price\n",
    "\n",
    "            # Model results\n",
    "            res = opt.solve(model, keepfiles=False, tee=True, warmstart=True)\n",
    "            model.solutions.store_to(res)\n",
    "\n",
    "            # Place results in DataFrame\n",
    "            try:\n",
    "                df = pd.DataFrame(res['Solution'][0])\n",
    "                permit_price_target_results = {'PERMIT_PRICE_TARGET': permit_price,\n",
    "                                               'results': df,\n",
    "                                               'PHI_DISCRETE': model.PHI_DISCRETE.expr()}\n",
    "            except:\n",
    "                permit_price_target_results = {'PERMIT_PRICE_TARGET': permit_price,\n",
    "                                               'results': 'infeasible'}\n",
    "                print('Permit price target {0} is infeasible'.format(permit_price))\n",
    "\n",
    "            # Try to print results\n",
    "            try:\n",
    "                print(model.PHI_DISCRETE.display())\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            print(model.tau.display())\n",
    "\n",
    "            # Save results\n",
    "\n",
    "            with open(os.path.join(paths.output_dir, filename), 'wb') as f:\n",
    "                pickle.dump(permit_price_target_results, f)\n",
    "\n",
    "run_permit_price_target_scenarios()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tps-parameterisation)",
   "language": "python",
   "name": "tps-parameterisation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
